{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "from collections import namedtuple, Counter\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up Twitter credentials using tweepy \n",
    "\n",
    "auth = tweepy.OAuthHandler('UEALJgD2o5lwpOeAeNhb9ceWX', 'JqB4i0TIqRizGtp97BovQN5iQDgA5BpF5tHHL0nZkUEANjxJuV')\n",
    "auth.set_access_token('732602583689367552-KeUxTRNYO2XwFux13Tp1yLoKyylMyO7', '0WWtEXmjOV1g732CBPs9Te8xQa7VKuSIBP9A0J4dxm1mL')\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use named tuples to keep info of interest for each tweet; keep urls to remove from text later\n",
    "\n",
    "Tweet = namedtuple('Tweet', ['text', 'tags', 'cited', 'urls', 'author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions to collect info of interest\n",
    "\n",
    "def get_hashtags(tweet):\n",
    "    tags = []\n",
    "    if len(tweet['entities']['hashtags']) > 0:\n",
    "        for tag in tweet['entities']['hashtags']:\n",
    "            tags.append(tag['text'])\n",
    "    return tags\n",
    "\n",
    "def get_citations(tweet):\n",
    "    citations = []\n",
    "    if len(tweet['entities']['user_mentions']) > 0:\n",
    "        for mention in tweet['entities']['user_mentions']:\n",
    "            citations.append(mention['screen_name'])\n",
    "    return citations\n",
    "\n",
    "def get_urls(tweet):\n",
    "    urls = []\n",
    "    if len(tweet['entities']['urls']) > 0:\n",
    "        for url in tweet['entities']['urls']:\n",
    "            urls.append(url['url'])\n",
    "    return urls\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull in tweets for each influencer listed in influencers.txt and process most recent 500 that are not retweets\n",
    "# store as lists in a dict with the influencer handles as keys \n",
    "\n",
    "all_tweets = {}\n",
    "with open('influencers.txt', 'r') as names:\n",
    "    for raw_name in names:\n",
    "        name = raw_name.strip()\n",
    "        tweets = tweepy.Cursor(api.user_timeline, id=name, tweet_mode='extended').items(800)\n",
    "        keepers = [tweet._json for tweet in tweets if 'retweeted_status' not in tweet._json]\n",
    "        all_tweets[name] = [Tweet(tweet['full_text'], get_hashtags(tweet), get_citations(tweet), get_urls(tweet),\n",
    "                                  name) for tweet in keepers[:500]]    \n",
    "\n",
    "names = all_tweets.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# also get the description each person uses\n",
    "\n",
    "descriptions = {}\n",
    "for name in names:\n",
    "    descriptions[name] = api.get_user(name)._json['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save data in case kernel hangs or is stopped\n",
    "\n",
    "with open('twitter_data.pydat', 'wb') as datafile:\n",
    "    pickle.dump(all_tweets, datafile)\n",
    "\n",
    "with open('twitter_descriptions.pydat', 'wb') as datafile:\n",
    "    pickle.dump(all_tweets, datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dict of Counters for the hashtags used by each person\n",
    "\n",
    "all_tags = {}\n",
    "for name in names:\n",
    "    tags = [tweet.tags for tweet in all_tweets[name]]\n",
    "    all_tags[name] = Counter(list(itertools.chain(*tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dict of Counters for the mentions made by each person\n",
    "\n",
    "all_mentions = {}\n",
    "for name in names:\n",
    "    mentions = [tweet.cited for tweet in all_tweets[name]]\n",
    "    all_mentions[name] = Counter(list(itertools.chain(*mentions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Counter for all the hashtags used\n",
    "\n",
    "tags = Counter()\n",
    "for name in names:\n",
    "    tags += all_tags[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1643"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect all hashtags used by more than one influencer for use as features\n",
    "# should have done this with the hashtags too\n",
    "\n",
    "tag_features = [tag for tag in list(tags.keys()) if sum([0 if all_tags[name][tag] == 0 else 1 for name in names]) > 1]\n",
    "len(tag_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Counter for all the mentions made\n",
    "\n",
    "mentions = Counter()\n",
    "for name in names:\n",
    "    mentions += all_mentions[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2784"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(mentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect all mentions made by more than one influencer for use as features\n",
    "\n",
    "mention_features = [mention for mention in list(mentions.keys()) if sum([0 if all_mentions[name][mention] == 0 else 1\n",
    "                                                                         for name in names]) > 1]\n",
    "len(mention_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find duplicates between tags and mentions\n",
    "\n",
    "duplicates = list(set(tag_features) & set(mention_features))\n",
    "len(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove from mentions since there are more of them\n",
    "# Note: this turned out to be unnecssary because tokenization split off the '#' but not the '@'\n",
    "\n",
    "mention_features = [mention for mention in mention_features if mention not in duplicates]\n",
    "len(mention_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create feature vectors comprising the counts for each tag and mention feature\n",
    "\n",
    "entities = pd.DataFrame(index=names, columns=(tag_features + mention_features))\n",
    "for name in names:\n",
    "    for tag in tag_features:\n",
    "        entities.loc[name, tag] = all_tags[name][tag]\n",
    "    for mention in mention_features:\n",
    "        entities.loc[name, mention] = all_tags[name][mention]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MeanShift, estimate_bandwidth, SpectralClustering, DBSCAN\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the features and perform a 2-component PCA analysis to use for graphing\n",
    "\n",
    "normed_ents = normalize(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.28006677,  0.15739239])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents_pca = PCA(2).fit(normed_ents)\n",
    "ents_pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try basic mean shift clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 3, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = MeanShift()\n",
    "ms.fit(normed_ents)\n",
    "ms.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean shift did not produce usable results, merely clustering all the authors together except for four clusters of one person each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of clusters is 2\n",
      "Cluster 0 comprises ['AndrewYNg', 'mrogati', 'analyticbridge', 'naval', 'hmason', 'EvanSinar']\n",
      "Cluster 1 comprises ['KirkDBorne', 'Ronald_vanLoon', 'craigbrownphd', 'bobehayes', 'BernardMarr', 'BigDataGal', 'data_nerd', 'kdnuggets', 'tamaradull']\n"
     ]
    }
   ],
   "source": [
    "# using silhouette scores over 1,000 runs to find the optimal number of clusters, then the best clusters\n",
    "\n",
    "clusters = []\n",
    "for _ in range(1000):\n",
    "    best_score = 0\n",
    "    num_labels = 0\n",
    "    for num_clusters in range(2, 7):\n",
    "        km = KMeans(num_clusters)\n",
    "        km.fit(normed_ents)\n",
    "        sil_score = silhouette_score(normed_ents, km.labels_)\n",
    "        if sil_score > best_score:\n",
    "            best_score = sil_score\n",
    "            num_labels = len(np.unique(km.labels_))\n",
    "    clusters.append(num_labels)\n",
    "\n",
    "optimal_num_clusters = Counter(clusters).most_common(1)[0][0]\n",
    "print('The optimal number of clusters is {}'.format(optimal_num_clusters))\n",
    "      \n",
    "best_labels = []\n",
    "best_score = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    km = KMeans(optimal_num_clusters)\n",
    "    km.fit(normed_ents)\n",
    "    sil_score = silhouette_score(normed_ents, km.labels_)\n",
    "    if sil_score > best_score:\n",
    "        best_score = sil_score\n",
    "        best_labels = km.labels_\n",
    "\n",
    "for i in range(optimal_num_clusters):\n",
    "    print('Cluster {} comprises {}'.format(i, [name for ix, name in enumerate(names) if best_labels[ix] == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 631), (6, 192), (4, 76), (3, 53), (5, 48)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(clusters).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm generated one cluster of authors with very few hashtags and mentions, and another comprising everyone else. This is a valid but not very sophisticated breakdown. The only really interesting result is that one author with a relatively high number of tags and mentions (EvanSinar, with 665) was put in the group with low numbers. Apparently he had few of these entities in common with others, resulting in low similarity scores as did authors with few entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KirkDBorne     : 2493 entities\n",
      "Ronald_vanLoon : 4092 entities\n",
      "craigbrownphd  : 563 entities\n",
      "bobehayes      : 1346 entities\n",
      "BernardMarr    : 953 entities\n",
      "BigDataGal     : 1273 entities\n",
      "AndrewYNg      : 6 entities\n",
      "mrogati        : 4 entities\n",
      "data_nerd      : 147 entities\n",
      "kdnuggets      : 265 entities\n",
      "analyticbridge : 0 entities\n",
      "naval          : 0 entities\n",
      "tamaradull     : 573 entities\n",
      "hmason         : 5 entities\n",
      "EvanSinar      : 665 entities\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    print('{:15}: {} entities'.format(name, entities.loc[name].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Twitter account descriptions are not very helpful for discovering similarities. Most are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groups = pd.DataFrame(index=names, columns=['description', 'label'])\n",
    "for name in names:\n",
    "    groups.loc[name, 'description'] = descriptions[name]\n",
    "groups.loc[:, 'label'] = best_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AndrewYNg :   Co-Founder of Coursera; Stanford CS adjunct faculty. Former head of Baidu AI Group/Google Brain. #ai #machinelearning, #deeplearning #MOOCs \n",
      "\n",
      "mrogati :   Data Science & AI advisor; fractional CDO. Former VP of Data @Jawbone & @LinkedIn data scientist. Equity Partner @DCVC. CMU CS PhD. \n",
      "\n",
      "analyticbridge :   Co-founded by Vincent Granville and part of the DSC community, our  focus is on data science, ML, AI, deep learning, dataviz, Hadoop, IoT, and BI. \n",
      "\n",
      "naval :   Present. \n",
      "\n",
      "hmason :   GM for Machine Learning at @Cloudera. Founder at @FastForwardLabs. Data Scientist in Residence at @accel. I â™¥ data and cheeseburgers. \n",
      "\n",
      "EvanSinar :   Chief Scientist & VP at Development Dimensions International (@DDIworld); Author & Top Influencer on #leadership | #dataviz | #analytics | #datascience | #iot \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KirkDBorne :   The Principal Data Scientist @BoozAllen. PhD Astrophysicist. Ex-Professor. Top Data Science and Big Data Influencer. https://t.co/f4gsbNc00C ðŸ“ŠðŸ“ˆðŸ”­ \n",
      "\n",
      "Ronald_vanLoon :   Helping data driven companies generating valueâ€¢Top10Influencer #BigData #DataScience #IoT #MachineLearning #AI #Analyticsâ€¢Follow Youtube\n",
      "https://t.co/1fTKAp3WNb \n",
      "\n",
      "craigbrownphd :   #Technology #Consultant (#techpreneur), #IT, #Data #Entrepreneur, #DataScience, #SME #CancerSurvivor #BigData #Cloud #AI #ML  https://t.co/7g098ndycZ \n",
      "\n",
      "bobehayes :   Researcher, writer and consultant, B.O.B. holds a PhD in industrial-organizational psychology. Interests in #datascience #cx #statistics #machinelearning \n",
      "\n",
      "BernardMarr :   Internationally best-selling author; keynote speaker; futurist; #business, #technology, and #data advisor to governments and companies. \n",
      "\n",
      "BigDataGal :   ðŸ‡ºðŸ‡¸ Data Strategist, Trainer & Biz Coach to Tech Professionals.  Tweets on #BigData #AI #IoT #WIT â†’Want to build your own profitable business? Join for FREEâ†“ \n",
      "\n",
      "data_nerd :   Data Scientist & Owner Analytical-Solution  DataNerd RT â‰  equal endorsement. Love sharing info about #DataScience #WIT  https://t.co/L9M6kSSaef \n",
      "\n",
      "kdnuggets :   Covering #AI, #Analytics, #BigData, #DataMining, #DataScience #MachineLearning, #DeepLearning.  Founded by Gregory Piatetsky-Shapiro. \n",
      "\n",
      "tamaradull :   Principal Evangelist @awscloud | Just livin' my best life in a geek's paradise! | #IoT #blockchain #opensource #cloudcomputing #emergingtech #womenintech \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in np.unique(best_labels):\n",
    "    for name in names:\n",
    "        if groups.loc[name, 'label'] == label:\n",
    "            print(name, ':  ', groups.loc[name, 'description'], '\\n')\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the clusters against the two principal components for a simple visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz = ents_pca.transform(entities)\n",
    "viz = pd.DataFrame(viz, index=names, columns=['pca0', 'pca1'])\n",
    "viz['label'] = best_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x113df5128>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAFgCAYAAACG+m8hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113df58d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = sns.cubehelix_palette(n_colors=2, rot=-0.7)\n",
    "sns.relplot(x='pca0', y='pca1', hue='label', data=viz, palette=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the plot utiizes only the first two components, which combine to explain less than half of the variance, and a few points are not individually visible since they are too close together, even here the clusters can be seen to comprise a large group occupying most of the plot and a group of outliers. With the exception of EvanSinar, the outlying cluster groups together people who included zero or very few hashtags and mentions common to others in their tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca0</th>\n",
       "      <th>pca1</th>\n",
       "      <th>label</th>\n",
       "      <th>num_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>analyticbridge</th>\n",
       "      <td>0.307586</td>\n",
       "      <td>0.012970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naval</th>\n",
       "      <td>0.307586</td>\n",
       "      <td>0.012970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrogati</th>\n",
       "      <td>1.428811</td>\n",
       "      <td>-0.320550</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmason</th>\n",
       "      <td>1.750313</td>\n",
       "      <td>-0.344222</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AndrewYNg</th>\n",
       "      <td>0.388220</td>\n",
       "      <td>-0.462557</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_nerd</th>\n",
       "      <td>-24.461976</td>\n",
       "      <td>-4.433887</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kdnuggets</th>\n",
       "      <td>-59.388896</td>\n",
       "      <td>-50.623356</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>craigbrownphd</th>\n",
       "      <td>-77.941819</td>\n",
       "      <td>121.987721</td>\n",
       "      <td>1</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tamaradull</th>\n",
       "      <td>-68.869570</td>\n",
       "      <td>102.686163</td>\n",
       "      <td>1</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EvanSinar</th>\n",
       "      <td>24.740672</td>\n",
       "      <td>-17.542021</td>\n",
       "      <td>0</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernardMarr</th>\n",
       "      <td>-141.123086</td>\n",
       "      <td>11.700477</td>\n",
       "      <td>1</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigDataGal</th>\n",
       "      <td>-282.748651</td>\n",
       "      <td>144.448768</td>\n",
       "      <td>1</td>\n",
       "      <td>1273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bobehayes</th>\n",
       "      <td>-215.895212</td>\n",
       "      <td>-160.654556</td>\n",
       "      <td>1</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KirkDBorne</th>\n",
       "      <td>-570.469546</td>\n",
       "      <td>-154.704880</td>\n",
       "      <td>1</td>\n",
       "      <td>2493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ronald_vanLoon</th>\n",
       "      <td>-466.987230</td>\n",
       "      <td>4.602898</td>\n",
       "      <td>1</td>\n",
       "      <td>4092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pca0        pca1  label  num_entities\n",
       "analyticbridge    0.307586    0.012970      0             0\n",
       "naval             0.307586    0.012970      0             0\n",
       "mrogati           1.428811   -0.320550      0             4\n",
       "hmason            1.750313   -0.344222      0             5\n",
       "AndrewYNg         0.388220   -0.462557      0             6\n",
       "data_nerd       -24.461976   -4.433887      1           147\n",
       "kdnuggets       -59.388896  -50.623356      1           265\n",
       "craigbrownphd   -77.941819  121.987721      1           563\n",
       "tamaradull      -68.869570  102.686163      1           573\n",
       "EvanSinar        24.740672  -17.542021      0           665\n",
       "BernardMarr    -141.123086   11.700477      1           953\n",
       "BigDataGal     -282.748651  144.448768      1          1273\n",
       "bobehayes      -215.895212 -160.654556      1          1346\n",
       "KirkDBorne     -570.469546 -154.704880      1          2493\n",
       "Ronald_vanLoon -466.987230    4.602898      1          4092"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz['num_entities'] = [sum(list(entities.iloc[ix])) for ix, name in enumerate(names)]\n",
    "\n",
    "viz.sort_values(by='num_entities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal KMeans grouping scheme of 2 clusters divides the authors into a group with very few common hashtags and mentions, and another group comprising authors with many common hashtags and mentions. EvanSinar is the exception, having 665 common hashtags and mentions but appearing in the group with very few of these. This might represent one network comprising 9 members and 6 people whose networks do not intersect with each other or those in the 9-member group, but the few-entities group also might comprise mostly authors whose style is to not use many hashtags or mentions. It would be interesting to look at the 6-cluster groupings, but this question cannot be settled given the data. Without all of the authors using a good number of common hashtags and/or mentions, clustering on these features will not produce useful results. Clustering on only those authors who do use large numbers of these entities could produce insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/anaconda/envs/thinkful/lib/python3.6/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SpectralClustering(n_clusters=4)\n",
    "sc.fit(entities)\n",
    "\n",
    "sc_labels = sc.labels_\n",
    "sc_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The warning arises from the fact that two of the authors have entity vectors that are all zeroes. This results in the graph being not fully connected. Forcing the algorithm to create four clusters produces one large cluster, two 2-person clusters and a 1-person cluster. At this point, the reults taken together indicate that clustering on the hashtags and mentions is not very useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try clustering using tf-idf vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gather the tweet texts as elements of a list in preparation for tf-idf vectorization\n",
    "# create a dataframe with a list for each author, for clustering, and one with indidvidual tweets and their authors\n",
    "\n",
    "tweet_texts = []\n",
    "tweet_authors = []\n",
    "tweets_by_author = pd.DataFrame(index=names, columns=['combined'])\n",
    "\n",
    "\n",
    "for name in names:\n",
    "    tweets = [re.sub('https?:\\/\\/[-\\w.]\\.?[a-zA-Z0-9]+\\/?[a-zA-Z0-9]*', '', tweet.text).strip()\n",
    "              for tweet in all_tweets[name]]\n",
    "    tweets_by_author.loc[name, 'combined'] = ' '.join(tweets)\n",
    "    tweet_texts.extend(tweets)\n",
    "    tweet_authors.extend([name] * len(tweets))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame({'text': tweet_texts, 'author': tweet_authors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Ronald_vanLoon</td>\n",
       "      <td>Six Ways #CIOs Can Drive #DigitalTransformatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Ronald_vanLoon</td>\n",
       "      <td>#SmartManufacturing clearly explained in 2 min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Ronald_vanLoon</td>\n",
       "      <td>Knowing the Difference between #UX and #UI Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Ronald_vanLoon</td>\n",
       "      <td>QIN #AI Phone on MioT Crowdfunding Platform\\nb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Ronald_vanLoon</td>\n",
       "      <td>#MachineLearning Summarized in One Picture\\nby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>craigbrownphd</td>\n",
       "      <td>Augmented reality, fog, and vision: Duke profe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>craigbrownphd</td>\n",
       "      <td>Openreach extends full-fibre broadband roll-ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>craigbrownphd</td>\n",
       "      <td>After Fetching a High Price, Time Magazine Mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>craigbrownphd</td>\n",
       "      <td>A Piece of Christmas Pie: The most criticized ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>craigbrownphd</td>\n",
       "      <td>Full-fibre broadband penetration reaches 5%  #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>craigbrownphd</td>\n",
       "      <td>Project Management â€“ Critical Success Factors ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                               text\n",
       "995   Ronald_vanLoon  Six Ways #CIOs Can Drive #DigitalTransformatio...\n",
       "996   Ronald_vanLoon  #SmartManufacturing clearly explained in 2 min...\n",
       "997   Ronald_vanLoon  Knowing the Difference between #UX and #UI Des...\n",
       "998   Ronald_vanLoon  QIN #AI Phone on MioT Crowdfunding Platform\\nb...\n",
       "999   Ronald_vanLoon  #MachineLearning Summarized in One Picture\\nby...\n",
       "1000   craigbrownphd  Augmented reality, fog, and vision: Duke profe...\n",
       "1001   craigbrownphd  Openreach extends full-fibre broadband roll-ou...\n",
       "1002   craigbrownphd  After Fetching a High Price, Time Magazine Mov...\n",
       "1003   craigbrownphd  A Piece of Christmas Pie: The most criticized ...\n",
       "1004   craigbrownphd  Full-fibre broadband penetration reaches 5%  #...\n",
       "1005   craigbrownphd  Project Management â€“ Critical Success Factors ..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reality check: the tweets in the dataframe should change authors at a multiple of 500\n",
    "\n",
    "tweets_df.loc[995:1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply tf-idf vectorization. Tweets are compact and rely on impact words more than grammatical constructions, so vocabulary seems more appropriate than tokenization and analysis involving parts of speech and phraseology. A question to be settled is whether individual tweets are too short to produce meaningful vectorizations, in which case groupings of several tweets might produce better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth_vectors = vectorizer.fit_transform(tweets_by_author['combined'])\n",
    "terms = vectorizer.get_feature_names()\n",
    "cluster_df = pd.DataFrame(auth_vectors.toarray(), index=names, columns=terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run the clustering algorithms on the vectorized combined tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.fit(normalize(cluster_df))\n",
    "ms.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 316), (8, 260), (6, 250), (5, 153), (9, 21)]\n",
      "The optimal number of clusters is 7\n",
      "Cluster 0 comprises ['analyticbridge']\n",
      "Cluster 1 comprises ['AndrewYNg', 'mrogati', 'naval', 'hmason']\n",
      "Cluster 2 comprises ['BernardMarr', 'EvanSinar']\n",
      "Cluster 3 comprises ['KirkDBorne', 'Ronald_vanLoon', 'kdnuggets']\n",
      "Cluster 4 comprises ['BigDataGal']\n",
      "Cluster 5 comprises ['bobehayes', 'data_nerd']\n",
      "Cluster 6 comprises ['craigbrownphd', 'tamaradull']\n"
     ]
    }
   ],
   "source": [
    "clusters = []\n",
    "cluster_data = normalize(cluster_df)\n",
    "for _ in range(1000):\n",
    "    best_score = -999\n",
    "    num_labels = 0\n",
    "    for num_clusters in range(5, 10):\n",
    "        km = KMeans(num_clusters)\n",
    "        km.fit(cluster_data)\n",
    "        sil_score = silhouette_score(cluster_data, km.labels_)\n",
    "        if sil_score > best_score:\n",
    "            best_score = sil_score\n",
    "            num_labels = num_clusters\n",
    "    clusters.append(num_labels)\n",
    "\n",
    "optimal_num_clusters = Counter(clusters).most_common(1)[0][0]\n",
    "print(Counter(clusters).most_common())\n",
    "print('The optimal number of clusters is {}'.format(optimal_num_clusters))\n",
    "      \n",
    "best_labels1 = []\n",
    "best_score1 = -999\n",
    "centers1 = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    km = KMeans(optimal_num_clusters)\n",
    "    km.fit(cluster_data)\n",
    "    sil_score = silhouette_score(cluster_data, km.labels_)\n",
    "    if sil_score > best_score1:\n",
    "        best_score1 = sil_score\n",
    "        best_labels1 = km.labels_\n",
    "        centers1 = km.cluster_centers_\n",
    "\n",
    "for i in range(optimal_num_clusters):\n",
    "    print('Cluster {} comprises {}'.format(i, [name for ix, name in enumerate(names) if best_labels1[ix] == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components:  37.0065018534\n",
      "Component 0:\n",
      "kdnuggets         0.491304\n",
      "BernardMarr       0.470505\n",
      "KirkDBorne        0.469460\n",
      "AndrewYNg         0.453781\n",
      "data_nerd         0.440996\n",
      "hmason            0.427634\n",
      "mrogati           0.426190\n",
      "tamaradull        0.400840\n",
      "bobehayes         0.358837\n",
      "naval             0.347496\n",
      "craigbrownphd     0.290169\n",
      "analyticbridge    0.278764\n",
      "Ronald_vanLoon    0.249605\n",
      "BigDataGal        0.244293\n",
      "EvanSinar         0.228506\n",
      "Name: 0, dtype: float64\n",
      "Component 1:\n",
      "KirkDBorne        0.576047\n",
      "kdnuggets         0.497440\n",
      "Ronald_vanLoon    0.274920\n",
      "bobehayes         0.201742\n",
      "BernardMarr       0.175465\n",
      "analyticbridge    0.125532\n",
      "EvanSinar         0.107659\n",
      "BigDataGal       -0.055732\n",
      "craigbrownphd    -0.079084\n",
      "data_nerd        -0.137469\n",
      "tamaradull       -0.164458\n",
      "AndrewYNg        -0.264794\n",
      "naval            -0.352711\n",
      "mrogati          -0.444565\n",
      "hmason           -0.473981\n",
      "Name: 1, dtype: float64\n",
      "Component 2:\n",
      "bobehayes         0.517187\n",
      "data_nerd         0.473918\n",
      "BigDataGal        0.425453\n",
      "tamaradull        0.323484\n",
      "craigbrownphd     0.141673\n",
      "EvanSinar         0.000815\n",
      "analyticbridge   -0.015976\n",
      "BernardMarr      -0.098645\n",
      "naval            -0.117102\n",
      "KirkDBorne       -0.167190\n",
      "AndrewYNg        -0.182140\n",
      "kdnuggets        -0.234987\n",
      "Ronald_vanLoon   -0.242198\n",
      "hmason           -0.256071\n",
      "mrogati          -0.308240\n",
      "Name: 2, dtype: float64\n",
      "Component 3:\n",
      "EvanSinar         0.450256\n",
      "BernardMarr       0.415336\n",
      "craigbrownphd     0.384158\n",
      "tamaradull        0.273333\n",
      "analyticbridge    0.202897\n",
      "naval             0.106206\n",
      "kdnuggets         0.008306\n",
      "AndrewYNg        -0.067967\n",
      "BigDataGal       -0.096337\n",
      "KirkDBorne       -0.190828\n",
      "mrogati          -0.198948\n",
      "data_nerd        -0.200852\n",
      "hmason           -0.203645\n",
      "Ronald_vanLoon   -0.332322\n",
      "bobehayes        -0.360951\n",
      "Name: 3, dtype: float64\n",
      "Component 4:\n",
      "analyticbridge    0.626798\n",
      "EvanSinar         0.264967\n",
      "BigDataGal        0.172338\n",
      "kdnuggets         0.139997\n",
      "hmason            0.128479\n",
      "mrogati           0.113165\n",
      "data_nerd         0.075664\n",
      "bobehayes         0.011229\n",
      "AndrewYNg        -0.057575\n",
      "KirkDBorne       -0.071097\n",
      "naval            -0.091214\n",
      "BernardMarr      -0.138053\n",
      "tamaradull       -0.251933\n",
      "Ronald_vanLoon   -0.391154\n",
      "craigbrownphd    -0.454742\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# reduce feature space to 5 principal components and choose two with the greatest spread among authors for graphing\n",
    "svd = TruncatedSVD(5)\n",
    "cluster_lsa = svd.fit_transform(cluster_data)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components: \", total_variance*100)\n",
    "\n",
    "authors_by_component = pd.DataFrame(cluster_lsa, index=names)\n",
    "for i in range(5):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(authors_by_component.loc[:,i].sort_values(ascending=False)[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13aad0e10>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdcAAAEWCAYAAAA0MN3QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130e84b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "authors_by_component['label'] = best_labels1\n",
    "cmap = sns.cubehelix_palette(n_colors=7, rot=-0.7)\n",
    "ax = sns.scatterplot(data=authors_by_component, x=1, y=4, hue='label', palette=cmap)\n",
    "ax.set_title('Clusters plotted against 2 of 5 principal components')\n",
    "ax.set_ylabel('pca4')\n",
    "ax.set_xlabel('pca1')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters are fairly well segregated on a 2-component plot. Look for commonalities in the 10 highest-scoring terms for each author. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>analyticbridge</th>\n",
       "      <td>conventional</td>\n",
       "      <td>statistical</td>\n",
       "      <td>posted</td>\n",
       "      <td>blogs</td>\n",
       "      <td>excel</td>\n",
       "      <td>cheat</td>\n",
       "      <td>logistic</td>\n",
       "      <td>qualitative</td>\n",
       "      <td>classification</td>\n",
       "      <td>comparison</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AndrewYNg</th>\n",
       "      <td>coursera</td>\n",
       "      <td>dl</td>\n",
       "      <td>stanford</td>\n",
       "      <td>conversational</td>\n",
       "      <td>moocs</td>\n",
       "      <td>nice</td>\n",
       "      <td>gpus</td>\n",
       "      <td>lets</td>\n",
       "      <td>nips2016</td>\n",
       "      <td>goodfellow_ian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrogati</th>\n",
       "      <td>chrisalbon</td>\n",
       "      <td>peteskomoroch</td>\n",
       "      <td>congratulations</td>\n",
       "      <td>dtunkelang</td>\n",
       "      <td>arnicas</td>\n",
       "      <td>oh</td>\n",
       "      <td>deck</td>\n",
       "      <td>caitie</td>\n",
       "      <td>imo</td>\n",
       "      <td>hmason</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naval</th>\n",
       "      <td>meditation</td>\n",
       "      <td>crypto</td>\n",
       "      <td>thread</td>\n",
       "      <td>listen</td>\n",
       "      <td>peace</td>\n",
       "      <td>awareness</td>\n",
       "      <td>investors</td>\n",
       "      <td>desire</td>\n",
       "      <td>meetings</td>\n",
       "      <td>moment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hmason</th>\n",
       "      <td>cloudera</td>\n",
       "      <td>fastforwardlabs</td>\n",
       "      <td>congratulations</td>\n",
       "      <td>happy</td>\n",
       "      <td>nyc</td>\n",
       "      <td>lol</td>\n",
       "      <td>mikeloukides</td>\n",
       "      <td>favorite</td>\n",
       "      <td>junior</td>\n",
       "      <td>amuellerml</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernardMarr</th>\n",
       "      <td>odsc</td>\n",
       "      <td>london</td>\n",
       "      <td>19th</td>\n",
       "      <td>keynote</td>\n",
       "      <td>speaker</td>\n",
       "      <td>leadership</td>\n",
       "      <td>talend</td>\n",
       "      <td>19</td>\n",
       "      <td>tickets</td>\n",
       "      <td>summit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EvanSinar</th>\n",
       "      <td>dataviz</td>\n",
       "      <td>leadership</td>\n",
       "      <td>hr</td>\n",
       "      <td>hranalytics</td>\n",
       "      <td>kdnuggets</td>\n",
       "      <td>storywithdata</td>\n",
       "      <td>central</td>\n",
       "      <td>visualizing</td>\n",
       "      <td>flowingdata</td>\n",
       "      <td>workplace</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KirkDBorne</th>\n",
       "      <td>datascientists</td>\n",
       "      <td>deeplearning</td>\n",
       "      <td>odsc</td>\n",
       "      <td>neuralnetworks</td>\n",
       "      <td>predictiveanalytics</td>\n",
       "      <td>coding</td>\n",
       "      <td>boozallen</td>\n",
       "      <td>west</td>\n",
       "      <td>rstats</td>\n",
       "      <td>datasciencectrl</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ronald_vanLoon</th>\n",
       "      <td>rt</td>\n",
       "      <td>cc</td>\n",
       "      <td>dl</td>\n",
       "      <td>deeplearning</td>\n",
       "      <td>digitaltransformation</td>\n",
       "      <td>internetofthings</td>\n",
       "      <td>infographics</td>\n",
       "      <td>videos</td>\n",
       "      <td>smartcity</td>\n",
       "      <td>iiot</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kdnuggets</th>\n",
       "      <td>deeplearning</td>\n",
       "      <td>sep</td>\n",
       "      <td>cheat</td>\n",
       "      <td>kdnuggets</td>\n",
       "      <td>biases</td>\n",
       "      <td>odsc</td>\n",
       "      <td>scratch</td>\n",
       "      <td>sheet</td>\n",
       "      <td>datascientists</td>\n",
       "      <td>sheets</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigDataGal</th>\n",
       "      <td>womenintech</td>\n",
       "      <td>callforcode</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>coding</td>\n",
       "      <td>professional</td>\n",
       "      <td>biz</td>\n",
       "      <td>clarify</td>\n",
       "      <td>portfolio</td>\n",
       "      <td>exec</td>\n",
       "      <td>tag</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bobehayes</th>\n",
       "      <td>customerexperience</td>\n",
       "      <td>ibmanalytics</td>\n",
       "      <td>sassoftware</td>\n",
       "      <td>analyticsx</td>\n",
       "      <td>callforcode</td>\n",
       "      <td>ibmwatson</td>\n",
       "      <td>cx</td>\n",
       "      <td>winwithai</td>\n",
       "      <td>data_nerd</td>\n",
       "      <td>cspenn</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_nerd</th>\n",
       "      <td>thecube</td>\n",
       "      <td>tmanspeaks</td>\n",
       "      <td>siliconangle</td>\n",
       "      <td>happy</td>\n",
       "      <td>psb_dc</td>\n",
       "      <td>zdnet</td>\n",
       "      <td>digitalcloudgal</td>\n",
       "      <td>datachick</td>\n",
       "      <td>youtube</td>\n",
       "      <td>wishes</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>craigbrownphd</th>\n",
       "      <td>huawei</td>\n",
       "      <td>5g</td>\n",
       "      <td>api</td>\n",
       "      <td>devops</td>\n",
       "      <td>dataanalytics</td>\n",
       "      <td>digitaltransformation</td>\n",
       "      <td>broadband</td>\n",
       "      <td>announced</td>\n",
       "      <td>honor</td>\n",
       "      <td>der</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tamaradull</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>emergingtech</td>\n",
       "      <td>techrepublic</td>\n",
       "      <td>forbes</td>\n",
       "      <td>sassoftware</td>\n",
       "      <td>smarthome</td>\n",
       "      <td>devices</td>\n",
       "      <td>opensource</td>\n",
       "      <td>writes</td>\n",
       "      <td>5g</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0                1                2  \\\n",
       "analyticbridge        conventional      statistical           posted   \n",
       "AndrewYNg                 coursera               dl         stanford   \n",
       "mrogati                 chrisalbon    peteskomoroch  congratulations   \n",
       "naval                   meditation           crypto           thread   \n",
       "hmason                    cloudera  fastforwardlabs  congratulations   \n",
       "BernardMarr                   odsc           london             19th   \n",
       "EvanSinar                  dataviz       leadership               hr   \n",
       "KirkDBorne          datascientists     deeplearning             odsc   \n",
       "Ronald_vanLoon                  rt               cc               dl   \n",
       "kdnuggets             deeplearning              sep            cheat   \n",
       "BigDataGal             womenintech      callforcode         keyboard   \n",
       "bobehayes       customerexperience     ibmanalytics      sassoftware   \n",
       "data_nerd                  thecube       tmanspeaks     siliconangle   \n",
       "craigbrownphd               huawei               5g              api   \n",
       "tamaradull                 nytimes     emergingtech     techrepublic   \n",
       "\n",
       "                             3                      4                      5  \\\n",
       "analyticbridge           blogs                  excel                  cheat   \n",
       "AndrewYNg       conversational                  moocs                   nice   \n",
       "mrogati             dtunkelang                arnicas                     oh   \n",
       "naval                   listen                  peace              awareness   \n",
       "hmason                   happy                    nyc                    lol   \n",
       "BernardMarr            keynote                speaker             leadership   \n",
       "EvanSinar          hranalytics              kdnuggets          storywithdata   \n",
       "KirkDBorne      neuralnetworks    predictiveanalytics                 coding   \n",
       "Ronald_vanLoon    deeplearning  digitaltransformation       internetofthings   \n",
       "kdnuggets            kdnuggets                 biases                   odsc   \n",
       "BigDataGal              coding           professional                    biz   \n",
       "bobehayes           analyticsx            callforcode              ibmwatson   \n",
       "data_nerd                happy                 psb_dc                  zdnet   \n",
       "craigbrownphd           devops          dataanalytics  digitaltransformation   \n",
       "tamaradull              forbes            sassoftware              smarthome   \n",
       "\n",
       "                              6            7               8                9  \\\n",
       "analyticbridge         logistic  qualitative  classification       comparison   \n",
       "AndrewYNg                  gpus         lets        nips2016   goodfellow_ian   \n",
       "mrogati                    deck       caitie             imo           hmason   \n",
       "naval                 investors       desire        meetings           moment   \n",
       "hmason             mikeloukides     favorite          junior       amuellerml   \n",
       "BernardMarr              talend           19         tickets           summit   \n",
       "EvanSinar               central  visualizing     flowingdata        workplace   \n",
       "KirkDBorne            boozallen         west          rstats  datasciencectrl   \n",
       "Ronald_vanLoon     infographics       videos       smartcity             iiot   \n",
       "kdnuggets               scratch        sheet  datascientists           sheets   \n",
       "BigDataGal              clarify    portfolio            exec              tag   \n",
       "bobehayes                    cx    winwithai       data_nerd           cspenn   \n",
       "data_nerd       digitalcloudgal    datachick         youtube           wishes   \n",
       "craigbrownphd         broadband    announced           honor              der   \n",
       "tamaradull              devices   opensource          writes               5g   \n",
       "\n",
       "                label  \n",
       "analyticbridge      0  \n",
       "AndrewYNg           1  \n",
       "mrogati             1  \n",
       "naval               1  \n",
       "hmason              1  \n",
       "BernardMarr         2  \n",
       "EvanSinar           2  \n",
       "KirkDBorne          3  \n",
       "Ronald_vanLoon      3  \n",
       "kdnuggets           3  \n",
       "BigDataGal          4  \n",
       "bobehayes           5  \n",
       "data_nerd           5  \n",
       "craigbrownphd       6  \n",
       "tamaradull          6  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = cluster_df.T\n",
    "groupings = pd.DataFrame(index=names, columns=range(10))\n",
    "for name in names:\n",
    "    groupings.loc[name, :] = words[name].sort_values(ascending=False)[0:10].index\n",
    "groupings['label'] = best_labels1\n",
    "groupings.sort_values(by='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to see much in common among the members of each cluster, but both members of cluster 2 talk about leadership. All three authors in cluster 3 highlight deep learning, and the two cluster 6 autors have a shared interest in 5g and applied tech in general.  The other groups have no obvious commonalities among members (clusters 1 and 5) or are individuals (clusters 0 and 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for words closest to the centroid of each cluster that score as high-impact words for cluster members, and see which of these words all members have in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-impact words close to the centroid and common to all members in each cluster\n",
      "\n",
      "\n",
      "Cluster 0:\n",
      "\n",
      " ['conventional', 'statistical', 'posted', 'blogs', 'excel', 'cheat', 'logistic', 'qualitative', 'classification', 'comparison', 'sheet', 'trees', 'handbook', 'shiny', 'apache', 'linear', 'mistakes', 'simplified', 'tests', 'clustering'] \n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "\n",
      " ['favorite', 'tweet', 'maybe'] \n",
      "\n",
      "\n",
      "Cluster 2:\n",
      "\n",
      " ['leadership', 'workplace'] \n",
      "\n",
      "\n",
      "Cluster 3:\n",
      "\n",
      " ['deeplearning', 'neuralnetworks'] \n",
      "\n",
      "\n",
      "Cluster 4:\n",
      "\n",
      " ['womenintech', 'callforcode', 'keyboard', 'coding', 'professional', 'biz', 'clarify', 'portfolio', 'tag', 'exec', 'sponsor', 'shirts', 'retro', 'greatly', '22', 'enter', 'dummies', 'incl', 'celebrate', 'ya'] \n",
      "\n",
      "\n",
      "Cluster 5:\n",
      "\n",
      " ['ibmanalytics', 'tmanspeaks', 'thecube', 'winwithai', 'psb_dc', 'datachick', 'kevin_jackson', 'cspenn', 'sardire', 'ht', 'mclynd', 'nyc', 'angelalipscomb', 'womenintech', 'majority'] \n",
      "\n",
      "\n",
      "Cluster 6:\n",
      "\n",
      " ['5g', 'announced', 'edgecomputing', 'oracle', 'private'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "centroids1 = centers1.argsort()[:, ::-1] \n",
    "words_df = pd.DataFrame(cluster_data, index=names, columns=terms)\n",
    "print('High-impact words close to the centroid and common to all members in each cluster\\n\\n')\n",
    "for i in range(optimal_num_clusters):\n",
    "    print('Cluster {}:'.format(i))\n",
    "    people = [name for name in names if groupings.loc[name, 'label'] == i]\n",
    "    words = []\n",
    "    for ind in centroids1[i]:\n",
    "        word = terms[ind]\n",
    "        common = True\n",
    "        for person in people:\n",
    "            if words_df.loc[person, word] <= 0.03: # the .03 threshold was obtained by trying various values\n",
    "                common = False\n",
    "                break\n",
    "        if common == True:\n",
    "            words.append(word)\n",
    "        if len(words) == 20:\n",
    "            break\n",
    "    print('\\n', words, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This programmatic analysis of the intra-group comonalities confirms and expands the insights from visual inspection of the top 10 words for each author.\n",
    "- Clusters 0 and 4, individuals, have large numbers of words, because neither has another person to filter for common words.\n",
    "- The words from cluster 1 words reveal no common topic of interest, but these are the authors who used few or no hashtags and mentions. So there is a logic to the grouping.\n",
    "- The cluster 2 authors both used the terms 'leadership' and 'workplace,' showing perhaps a shared interest in management.\n",
    "- For cluster 3, the authors had 'neuralnetworks' as well as 'deeplearning' in common, strengthening the topical bond.\n",
    "- There is a surprise in that the cluster 5 authors share many terms in common. Rather than topics, however, they seem to comprise mostly mentions and groups, suggesting these authors have overlapping work and/or social networks.\n",
    "- The cluster 6 authors shared 'edgecomputing' as well as '5g,' but also 'oracle,' enterprise software. These seem to suggest an applications-oriented focus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__It should be noted__*, however, that a number of the common influential \"words\" are joined phrases, indicating that they likely were hashtags (or mentions). This contaminates the results, since, for instance, any number of authors might have written about 'deep learning,' even to the point where 'deep' and 'learning' on their own ended up with very low scores, or maybe were even excluded because they occurred too frequently. This seems an intractable problem with the tf-idf approach employed. A bag-of-words approach would have the converse problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thematic topic(s) of each cluster can be analyzed by looking at the terms closest to its centroid, regardless of which members used those terms or had them in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words closest to the centroid of each cluster\n",
      "\n",
      "\n",
      "Cluster 0:\n",
      "['conventional', 'statistical', 'posted', 'blogs', 'excel', 'cheat', 'logistic', 'qualitative', 'classification', 'comparison'] \n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "['congratulations', 'chrisalbon', 'coursera', 'cloudera', 'happy', 'peteskomoroch', 'fastforwardlabs', 'stanford', 'favorite', 'dl'] \n",
      "\n",
      "\n",
      "Cluster 2:\n",
      "['leadership', 'dataviz', 'odsc', 'london', 'hr', '19th', 'keynote', 'speaker', 'hranalytics', 'workplace'] \n",
      "\n",
      "\n",
      "Cluster 3:\n",
      "['deeplearning', 'datascientists', 'rt', 'cc', 'odsc', 'neuralnetworks', 'sep', 'cheat', 'digitaltransformation', 'kdnuggets'] \n",
      "\n",
      "\n",
      "Cluster 4:\n",
      "['womenintech', 'callforcode', 'keyboard', 'coding', 'professional', 'biz', 'clarify', 'portfolio', 'tag', 'exec'] \n",
      "\n",
      "\n",
      "Cluster 5:\n",
      "['customerexperience', 'ibmanalytics', 'tmanspeaks', 'thecube', 'winwithai', 'psb_dc', 'sassoftware', 'analyticsx', 'callforcode', 'datachick'] \n",
      "\n",
      "\n",
      "Cluster 6:\n",
      "['huawei', '5g', 'nytimes', 'techrepublic', 'emergingtech', 'forbes', 'api', 'sassoftware', 'devops', 'dataanalytics'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Words closest to the centroid of each cluster\\n\\n')\n",
    "for i in range(optimal_num_clusters):\n",
    "    print('Cluster {}:'.format(i))\n",
    "    words = [terms[ind] for ind in centroids1[i][:10]]\n",
    "    print(words, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results solidify the already established themes. Cluster 2 has 'hr' and 'hranalytics,' in addition to 'leadership' and 'workplace,' further emphasizing management concerns, but it also has 'odsc,' 'london,' '19,' 'keynote' and 'speaker,' suggesting the two authors in this group were strongly involved with the ODSC Europe conference held Sept. 19-22 this year in London. gains a sharper enterprise focus with the addition of 'sassoftware,' 'devops' and 'dataanalytics.' For cluster 3, 'datascientists,' 'digitaltransformation' and 'kdnuggets' extend the AI/machine learning emphasis of deep learning and neural networks. Similarly, 'emergingtech,' 'sassoftware,' 'dataanalytics' and 'devops' fit with the cluster 6 emphasis on applied data sciece and emerging technologies. The fact that there is little overlap between the central terms of clusters 1 and 5 and the high-scoring terms, respectively, of their members supports the idea that the connections here have more to do with things beside topical content â€” low use of hashtags and mentions for cluster 1 and network relationships for cluster 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 3 0 0 0 0 0 0 0 1 1 2 0 0] \n",
      "\n",
      "Cluster 0 comprises ['KirkDBorne', 'bobehayes', 'BernardMarr', 'BigDataGal', 'AndrewYNg', 'mrogati', 'data_nerd', 'kdnuggets', 'hmason', 'EvanSinar']\n",
      "Cluster 1 comprises ['analyticbridge', 'naval']\n",
      "Cluster 2 comprises ['Ronald_vanLoon', 'tamaradull']\n",
      "Cluster 3 comprises ['craigbrownphd']\n",
      "Cluster 4 comprises []\n",
      "Cluster 5 comprises []\n",
      "Cluster 6 comprises []\n"
     ]
    }
   ],
   "source": [
    "sc = SpectralClustering(n_clusters=optimal_num_clusters)\n",
    "\n",
    "best_score = -999\n",
    "best_sc_labels = []\n",
    "for _ in range(1000):\n",
    "    sc.fit(cluster_data)\n",
    "    sil_score = silhouette_score(cluster_data, sc.labels_)\n",
    "    if sil_score > best_score:\n",
    "        best_score = sil_score\n",
    "        best_sc_labels = sc.labels_\n",
    "\n",
    "\n",
    "print(sc_labels, '\\n')\n",
    "for i in range(7):\n",
    "    print('Cluster {} comprises {}'.format(i, [name for ix, name in enumerate(names) if sc_labels[ix] == i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are not as observably coherent as those from K-Means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets_df['text'], tweets_df['author'], test_size=0.4,\n",
    "                                                    random_state=0, stratify=tweets_df['author'])\n",
    "\n",
    "\n",
    "# apply the vectorizer, but don't fit on the test set to prevent data leakage\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance with cross-validation scoring of the basic estimators, using the Matthews correlation coefficient, which uses all the metrics from the confusion matrix. See if classification into clusters (7 classes) produces significantly better results thn classifying by individual authors (15 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.46234669  0.50964209  0.49930392  0.49227999]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=20)\n",
    "\n",
    "print(cross_val_score(rfc, X_train_tfidf, y_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525515126777\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train_tfidf, y_train)\n",
    "print(matthews_corrcoef(y_test, rfc.predict(X_test_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create cluster targets\n",
    "\n",
    "groupings = dict(zip(names, best_labels))\n",
    "y_groupings_train = y_train.apply(lambda x: groupings[x])\n",
    "y_groupings_test = y_test.apply(lambda x: groupings[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5606641   0.52582477  0.56111559  0.57701059]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(rfc, X_train_tfidf, y_groupings_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.60347114  0.62307522  0.59202515  0.62965837]\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "print(cross_val_score(gbc, X_train_tfidf, y_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.66994175  0.665331    0.67909601  0.68573099]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(gbc, X_train_tfidf, y_groupings_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63869872  0.64720024  0.64028847  0.66333377]\n"
     ]
    }
   ],
   "source": [
    "lrc = LogisticRegression()\n",
    "\n",
    "print(cross_val_score(lrc, X_train_tfidf, y_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65598059  0.65292284  0.63555165  0.66805898]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(lrc, X_train_tfidf, y_groupings_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10898367  0.11756348  0.09299779  0.08517069]\n"
     ]
    }
   ],
   "source": [
    "knc = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "print(cross_val_score(knc, X_train_tfidf, y_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5515781   0.53595922  0.52707939  0.54555063]\n"
     ]
    }
   ],
   "source": [
    "ada_rf = AdaBoostClassifier(rfc)\n",
    "\n",
    "print(cross_val_score(ada_rf, X_train_tfidf, y_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.58022999  0.59000165  0.58090456  0.60682544]\n"
     ]
    }
   ],
   "source": [
    "ada_lr = AdaBoostClassifier(lrc)\n",
    "print(cross_val_score(ada_lr, X_train_tfidf, y_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cluster labels instead of individuals as the targets did not significantly improve the results, despite reducing the number of classes by half. The one exception to this was with gradient boosting, where the score increased by about 10%. Gradient boosting also had the highest score on the 15-label (individual) classification. But does it overfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.637056642137\n"
     ]
    }
   ],
   "source": [
    "gbc.fit(X_train_tfidf, y_train)\n",
    "print(matthews_corrcoef(y_test, gbc.predict(X_test_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.699756882177\n"
     ]
    }
   ],
   "source": [
    "gbc.fit(X_train_tfidf, y_groupings_train)\n",
    "print(matthews_corrcoef(y_groupings_test, gbc.predict(X_test_tfidf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if lemmatizing the tweets improves performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(input):\n",
    "    tokens = nlp(input)\n",
    "    output = [token.lemma_ for token in tokens\n",
    "              if token.lemma_ not in ['#', \",'\", ',\"', \".'\", '.\"', \"?'\", '?\"']\n",
    "              and not (token.is_punct and len(token.lemma_) == 1) # keep two-character emoticons, e.g. :) or ;) \n",
    "              and not token.is_stop]\n",
    "    return ' '.join(output).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tokenized = X_train.apply(tokenize)\n",
    "X_test_tokenized = X_test.apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tok_tfidf = vectorizer.fit_transform(X_train_tokenized)\n",
    "X_test_tok_tfidf = vectorizer.transform(X_test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63302328  0.63978736  0.65983682  0.66226785]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(lrc, X_train_tok_tfidf, y_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65210307  0.66424054  0.64047843  0.69511199]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(lrc, X_train_tok_tfidf, y_groupings_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.61004454  0.59668689  0.57822303  0.63477301]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(gbc, X_train_tok_tfidf, y_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6629701   0.65984947  0.6777627   0.68588167]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(gbc, X_train_tok_tfidf, y_groupings_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant improvement, and the cross-eval scores for gradient boosting are a little less consistent. See if adding bigrams improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4506"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(ngram_range=(1,2), \n",
    "                              max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                              min_df=2, # only use words that appear at least twice\n",
    "                              max_features=6000, # increase to ensure that at least the 1,500 highest-scoring bigrams are used\n",
    "                              stop_words='english', \n",
    "                              lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                              use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                              norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                              smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf2 = vectorizer2.fit_transform(X_train)\n",
    "X_test_tfidf2 = vectorizer2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63745287  0.64613577  0.64399704  0.66797534]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(lrc, X_train_tfidf2, y_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.66487708  0.66872642  0.65288231  0.6764393 ]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(lrc, X_train_tfidf2, y_groupings_train, scoring=mcc_scorer, cv=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither tokenization nor adding bigrams significantly improved performance, so tune the hyperparameters for logistic regression on the basic tf-idf data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrc_params = [{'penalty': ['l1', 'l2'], 'tol': [1e-4, 1e-3, 1e-2], 'C': [3, 5, 7, 10],\n",
    "               'solver': ['liblinear'], 'multi_class': ['ovr']},\n",
    "              { 'penalty': ['l2'], 'tol': [1e-4, 1e-3, 1e-2], 'C': [3, 5, 7, 10],\n",
    "               'solver': ['newton-cg', 'lbfgs'], 'multi_class': ['ovr', 'multinomial']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(rand, X=tweets_df['text'], Y=tweets_df['author'], transformer=None,\n",
    "             clf=lrc, params=lrc_params, t_size=0.4):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=t_size, random_state=rand, stratify=Y)\n",
    "    if transformer:\n",
    "        X_train = transformer.fit_transform(X_train)\n",
    "        X_test = transformer.transform(X_test)\n",
    "    model = GridSearchCV(clf, param_grid=params, scoring=mcc_scorer)\n",
    "    model.fit(X_train, Y_train)\n",
    "    print('Optimal parameters: {}'.format(model.best_params_))\n",
    "    preds = model.predict(X_test)\n",
    "    print('Matthews score: {}'.format(matthews_corrcoef(Y_test, preds)))\n",
    "    # The following three lines would need to be modified to apply to a multi-class setting\n",
    "    # print('ROC-AUC score: {}'.format(roc_auc_score(Y_test, preds)))\n",
    "    # residuals = pd.DataFrame(model.best_estimator_.decision_function(Xr_test))\n",
    "    # plt.scatter(residuals.index, residuals)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters: {'C': 5, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "Matthews score: 0.6895957737101615\n"
     ]
    }
   ],
   "source": [
    "opt1 = optimize(rand=7, transformer=vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters: {'C': 5, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "Matthews score: 0.6856909270155424\n"
     ]
    }
   ],
   "source": [
    "opt2 = optimize(rand=29, transformer=vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters: {'C': 7, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "Matthews score: 0.6730672687972501\n"
     ]
    }
   ],
   "source": [
    "opt1 = optimize(rand=41, transformer=vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems relatively stable. Further tweaking could probably nail down the optimal C value between 4 and 5, and the tolerance between .oo1 and .0001, but the optimation consistently selected the liblinear solver with the L2 penalty and the one-vs-rest multi-class strategy. The model woul correctly assign the author of the tweet (among the 15 authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters: {'C': 7, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01}\n",
      "Matthews score: 0.6941464651260699\n"
     ]
    }
   ],
   "source": [
    "opt1 = optimize(rand=7, transformer=vectorizer, t_size=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters: {'C': 3, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "Matthews score: 0.6931456101358475\n"
     ]
    }
   ],
   "source": [
    "opt1 = optimize(rand=7, transformer=vectorizer, t_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is not overly sensitive to the relative sizes of the train/test split, although both 65/35 (best score) and 70/30 perform slightly better than 60/40. The decrease in the C parameter on the 70/30 split, however, might indicate that the model is starting to overfit, with larger regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try clustering again, adding bigrams into the tf-idf vector features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 330), (7, 225), (5, 220), (8, 129), (9, 96)]\n",
      "The optimal number of clusters is 6\n",
      "Cluster 0 comprises ['bobehayes', 'data_nerd']\n",
      "Cluster 1 comprises ['AndrewYNg', 'mrogati', 'naval', 'hmason']\n",
      "Cluster 2 comprises ['KirkDBorne', 'Ronald_vanLoon', 'kdnuggets', 'analyticbridge']\n",
      "Cluster 3 comprises ['craigbrownphd', 'tamaradull']\n",
      "Cluster 4 comprises ['BigDataGal']\n",
      "Cluster 5 comprises ['BernardMarr', 'EvanSinar']\n"
     ]
    }
   ],
   "source": [
    "auth_vectors2 = vectorizer2.fit_transform(tweets_by_author['combined'])\n",
    "terms2 = vectorizer2.get_feature_names()\n",
    "cluster_df2 = pd.DataFrame(auth_vectors2.toarray(), index=names, columns=terms2)\n",
    "\n",
    "clusters = []\n",
    "cluster_data2 = normalize(cluster_df2)\n",
    "for _ in range(1000):\n",
    "    best_score = -999\n",
    "    num_labels = 0\n",
    "    for num_clusters in range(5, 10):\n",
    "        km = KMeans(num_clusters)\n",
    "        km.fit(cluster_data2)\n",
    "        sil_score = silhouette_score(cluster_data2, km.labels_)\n",
    "        if sil_score > best_score:\n",
    "            best_score = sil_score\n",
    "            num_labels = num_clusters\n",
    "    clusters.append(num_labels)\n",
    "\n",
    "optimal_num_clusters = Counter(clusters).most_common(1)[0][0]\n",
    "print(Counter(clusters).most_common())\n",
    "print('The optimal number of clusters is {}'.format(optimal_num_clusters))\n",
    "      \n",
    "best_labels = []\n",
    "best_score = -999\n",
    "\n",
    "for _ in range(1000):\n",
    "    km = KMeans(optimal_num_clusters)\n",
    "    km.fit(cluster_data2)\n",
    "    sil_score = silhouette_score(cluster_data2, km.labels_)\n",
    "    if sil_score > best_score:\n",
    "        best_score = sil_score\n",
    "        best_labels = km.labels_\n",
    "\n",
    "for i in range(optimal_num_clusters):\n",
    "    print('Cluster {} comprises {}'.format(i, [name for ix, name in enumerate(names) if best_labels[ix] == i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the individuals has been brought into the 'deep learning' group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last variation will be to match hashtags to concatenated bigrams, and add as many bigrams as matches to the combined tweets for each author. This will allow similarity measures to factor in matches between the bigram and hashtag variants of common two-word phrases, such as 'deep learning,' across authors. This will be used only for clustering, though, since hashtags vs. bigrams is a useful difference for classifiction purposes. It is expected that this could result in fewer, larger clusters by generating larger similarity scores between authors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer3 = TfidfVectorizer(ngram_range=(2,2), \n",
    "                              max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                              min_df=2, # only use words that appear at least twice\n",
    "                              stop_words='english', \n",
    "                              lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                              use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                              norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                              smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer3.fit_transform(tweets_by_author['combined'])\n",
    "bigrams = vectorizer3.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the bigrams\n",
    "\n",
    "def expand(author):\n",
    "    addition = []\n",
    "    for bigram in bigrams:\n",
    "        num_tags = all_tags[author][bigram.replace(' ', '')]\n",
    "        if num_tags:\n",
    "            addition.extend([bigram] * num_tags)\n",
    "    return ' ' + ' '.join(addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transfer = pd.DataFrame(index=names, columns=['extended'])\n",
    "for name in names:\n",
    "    transfer.loc[name, 'extended'] = tweets_by_author.loc[name, 'combined'] + expand(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_vectors3 = vectorizer2.fit_transform(transfer['extended'])\n",
    "terms3 = vectorizer2.get_feature_names()\n",
    "cluster_df3 = pd.DataFrame(auth_vectors3.toarray(), index=names, columns=terms3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 339), (6, 335), (4, 197), (7, 121), (3, 8)]\n",
      "The optimal number of clusters is 5\n",
      "Cluster 0 comprises ['KirkDBorne', 'Ronald_vanLoon', 'BernardMarr', 'kdnuggets', 'analyticbridge']\n",
      "Cluster 1 comprises ['AndrewYNg', 'mrogati', 'naval', 'hmason']\n",
      "Cluster 2 comprises ['bobehayes', 'data_nerd']\n",
      "Cluster 3 comprises ['EvanSinar']\n",
      "Cluster 4 comprises ['craigbrownphd', 'BigDataGal', 'tamaradull']\n"
     ]
    }
   ],
   "source": [
    "clusters = []\n",
    "cluster_data3 = normalize(cluster_df3)\n",
    "for _ in range(1000):\n",
    "    best_score = -999\n",
    "    num_labels = 0\n",
    "    for num_clusters in range(3, 8):\n",
    "        km = KMeans(num_clusters)\n",
    "        km.fit(cluster_data3)\n",
    "        sil_score = silhouette_score(cluster_data3, km.labels_)\n",
    "        if sil_score > best_score:\n",
    "            best_score = sil_score\n",
    "            num_labels = num_clusters\n",
    "    clusters.append(num_labels)\n",
    "\n",
    "optimal_num_clusters = Counter(clusters).most_common(1)[0][0]\n",
    "print(Counter(clusters).most_common())\n",
    "print('The optimal number of clusters is {}'.format(optimal_num_clusters))\n",
    "      \n",
    "best_labels3 = []\n",
    "best_score3 = -999\n",
    "centers3 = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    km = KMeans(optimal_num_clusters)\n",
    "    km.fit(cluster_data3)\n",
    "    sil_score = silhouette_score(cluster_data3, km.labels_)\n",
    "    if sil_score > best_score3:\n",
    "        best_score3 = sil_score\n",
    "        best_labels3 = km.labels_\n",
    "        centers3 = km.cluster_centers_\n",
    "\n",
    "for i in range(optimal_num_clusters):\n",
    "    print('Cluster {} comprises {}'.format(i, [name for ix, name in enumerate(names) if best_labels3[ix] == i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique produces the most compact clustering. The number of clusters has come down to 5, with the other former individual joining the group that seems to be based on network connections. But EvanSinar, who despite using more than 600 hashtags and mentions initially was put in with the group that used few or none of these entities, now is grouped as an individual. This would support a hypothesis that this author used entities not used by the other authors, since \"double counting\" these as bigrams would isolate this person from both those that used more common entities and those that used few or none. It appears that hashtags and mentions dominated the clustering even when the full tweet texts were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-impact words close to the centroid and common to all members in each cluster\n",
      "\n",
      "\n",
      "Cluster 0:\n",
      "\n",
      " ['neural network', 'ebook'] \n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "\n",
      " ['happy', 'favorite', 'tweet', 'sorry', 'thread', 'enjoy', 'maybe', 'hour', 'outside', 'looking forward', 'wouldn', 'disagree', 'english', 'saying', 'imagine', 'couldn', 'beautiful', 'invest', 'easily', 'wish'] \n",
      "\n",
      "\n",
      "Cluster 2:\n",
      "\n",
      " ['ibmanalytics', 'tmanspeaks', 'machinelearning datascience', 'thecube', 'psb_dc', 'winwithai', 'datachick', 'analyticsx', 'kevin_jackson', 'cspenn', 'callforcode', 'siliconangle', 'sardire', 'ht', 'mclynd', 'nyc', 'customer experience', 'ibmanalytics ibm', 'loyalty', 'womenintech'] \n",
      "\n",
      "\n",
      "Cluster 3:\n",
      "\n",
      " ['viz data', 'data viz', 'viz', 'dataviz', 'leadership', 'hr', 'hranalytics', 'kdnuggets', 'data visualization', 'storywithdata', 'kdnuggets datascience', 'central', 'visualizing', 'flowingdata', 'workplace', 'forecast', 'storytelling', 'futureofwork', 'harvardbiz', 'quartz'] \n",
      "\n",
      "\n",
      "Cluster 4:\n",
      "\n",
      " ['ai iot', 'iot bigdata', '5g', 'bigdata iot', 'bigdata ai', 'devices', 'internet things', 'device', 'major', 'private', 'iot ai', 'connectivity', 'sector', 'ericsson', 'industrial', 'states', 'greater', 'deployment', 'rest', 'despite'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "centroids3 = centers3.argsort()[:, ::-1]\n",
    "words_df3 = pd.DataFrame(cluster_data3, index=names, columns=terms3)\n",
    "groupings3 = dict(zip(names, best_labels3))\n",
    "print('High-impact words close to the centroid and common to all members in each cluster\\n\\n')\n",
    "for i in range(optimal_num_clusters):\n",
    "    print('Cluster {}:'.format(i))\n",
    "    people = [name for name in names if groupings3[name] == i]\n",
    "    words = []\n",
    "    for ind in centroids3[i]:\n",
    "        word = terms3[ind]\n",
    "        common = True\n",
    "        for person in people:\n",
    "            if words_df3.loc[person, word] <= 0.001: # threshold lowered to produce results for cluster 0\n",
    "                common = False\n",
    "                break\n",
    "        if common == True:\n",
    "            words.append(word)\n",
    "        if len(words) == 20:\n",
    "            break\n",
    "    print('\\n', words, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the clusters grow larger, it is more difficult to find terms that all members have in common. But the terms closest to the cluster centers would still sketch common themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words closest to the centroid of each cluster\n",
      "\n",
      "\n",
      "Cluster 0:\n",
      "['deeplearning', 'rt', 'odsc', 'datascientists', 'cc', 'join learn', 'conventional', 'cheat', 'accelerate ai', 'datascience machinelearning'] \n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "['congratulations', 'chrisalbon', 'cloudera', 'coursera', 'happy', 'peteskomoroch', 'fastforwardlabs', 'favorite', 'stanford', 'tweet'] \n",
      "\n",
      "\n",
      "Cluster 2:\n",
      "['artificialintelligence machinelearning', 'ibmanalytics', 'customerexperience', 'tmanspeaks', 'machinelearning datascience', 'thecube', 'psb_dc', 'winwithai', 'datachick', 'analyticsx'] \n",
      "\n",
      "\n",
      "Cluster 3:\n",
      "['viz data', 'data viz', 'viz', 'dataviz', 'leadership', 'hr', 'hranalytics', 'kdnuggets', 'data visualization', 'storywithdata'] \n",
      "\n",
      "\n",
      "Cluster 4:\n",
      "['huawei', 'ai iot', 'iot bigdata', '5g', 'nytimes', 'bigdata automation', 'ai datascience', 'womenintech', 'datascience bigdata', 'techrepublic'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Words closest to the centroid of each cluster\\n\\n')\n",
    "for i in range(optimal_num_clusters):\n",
    "    print('Cluster {}:'.format(i))\n",
    "    words = [terms3[ind] for ind in centroids3[i][:10]]\n",
    "    print(words, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The former group that seemed to highlight management concerns but also might have had a stronger connection to the ODSC Europe conference has disappeared, with both members now assigned to other clusters. The largest now is the AI/machine learning group, cluster 0, comprising KirkDBorne, Ronald_vanLoon, BernardMarr, kdnuggets and analyticbridge. Next comes the cluster 1 group of four authors â€” AndrewYNg, mrogati, naval, hmason â€” who used few or no hashtags and mentions. The emerging technology group, cluster 4, now has three members: craigbrownphd, BigDataGal and tamaradull. Interestingly, cluster 2, the two authors seemingly grouped together via networking â€” bobehayes and data_nerd â€” now has some strong thematic content having to do with machine learning and AI. But it remains separate. Also interesting is that cluster 3, the only remaining group of one, EvanSinar, has an especially tight focus on data stories and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039678490663841451"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031624647864379983"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides its tighter thematic ties, this final 5-cluster grouping has a silhouette score of .032, which is 25% lower than the .040 score of the 7-cluster grouping based on the initial tf=idf vectorization of the tweet texts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
